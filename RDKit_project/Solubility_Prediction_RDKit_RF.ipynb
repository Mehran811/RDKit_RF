{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solubility Prediction by Random Forest Algorithem Using RDKit 2D and 3D Descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The formula is modeling solubility as a linear function of three factors:**\n",
    "\n",
    "- logP (lipophilicity): Solubility decreases as logP increases (more hydrophobic molecules are less soluble in water).\n",
    "\n",
    "- Molecular weight (mol_wt): Solubility increases slightly as molecular weight increases.\n",
    "\n",
    "- Hydrogen bond donors (h_bond_donors): Solubility decreases as the number of hydrogen bond donors increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:44:45] SMILES Parse Error: syntax error while parsing: InvalidSMILES123\n",
      "[17:44:45] SMILES Parse Error: check for mistakes around position 3:\n",
      "[17:44:45] InvalidSMILES123\n",
      "[17:44:45] ~~^\n",
      "[17:44:45] SMILES Parse Error: Failed parsing SMILES 'InvalidSMILES123' for input: 'InvalidSMILES123'\n",
      "[17:44:45] SMILES Parse Error: syntax error while parsing: NaCl\n",
      "[17:44:45] SMILES Parse Error: check for mistakes around position 2:\n",
      "[17:44:45] NaCl\n",
      "[17:44:45] ~^\n",
      "[17:44:45] SMILES Parse Error: Failed parsing SMILES 'NaCl' for input: 'NaCl'\n",
      "[17:44:45] SMILES Parse Error: syntax error while parsing: InvalidSMILES123\n",
      "[17:44:45] SMILES Parse Error: check for mistakes around position 3:\n",
      "[17:44:45] InvalidSMILES123\n",
      "[17:44:45] ~~^\n",
      "[17:44:45] SMILES Parse Error: Failed parsing SMILES 'InvalidSMILES123' for input: 'InvalidSMILES123'\n",
      "[17:44:45] SMILES Parse Error: syntax error while parsing: NaCl\n",
      "[17:44:45] SMILES Parse Error: check for mistakes around position 2:\n",
      "[17:44:45] NaCl\n",
      "[17:44:45] ~^\n",
      "[17:44:45] SMILES Parse Error: Failed parsing SMILES 'NaCl' for input: 'NaCl'\n",
      "[17:44:45] SMILES Parse Error: syntax error while parsing: InvalidSMILES123\n",
      "[17:44:45] SMILES Parse Error: check for mistakes around position 3:\n",
      "[17:44:45] InvalidSMILES123\n",
      "[17:44:45] ~~^\n",
      "[17:44:45] SMILES Parse Error: Failed parsing SMILES 'InvalidSMILES123' for input: 'InvalidSMILES123'\n",
      "[17:44:45] SMILES Parse Error: syntax error while parsing: NaCl\n",
      "[17:44:45] SMILES Parse Error: check for mistakes around position 2:\n",
      "[17:44:45] NaCl\n",
      "[17:44:45] ~^\n",
      "[17:44:45] SMILES Parse Error: Failed parsing SMILES 'NaCl' for input: 'NaCl'\n",
      "[17:44:45] SMILES Parse Error: syntax error while parsing: InvalidSMILES123\n",
      "[17:44:45] SMILES Parse Error: check for mistakes around position 3:\n",
      "[17:44:45] InvalidSMILES123\n",
      "[17:44:45] ~~^\n",
      "[17:44:45] SMILES Parse Error: Failed parsing SMILES 'InvalidSMILES123' for input: 'InvalidSMILES123'\n",
      "[17:44:45] SMILES Parse Error: syntax error while parsing: NaCl\n",
      "[17:44:45] SMILES Parse Error: check for mistakes around position 2:\n",
      "[17:44:45] NaCl\n",
      "[17:44:45] ~^\n",
      "[17:44:45] SMILES Parse Error: Failed parsing SMILES 'NaCl' for input: 'NaCl'\n",
      "[17:44:45] SMILES Parse Error: syntax error while parsing: InvalidSMILES123\n",
      "[17:44:45] SMILES Parse Error: check for mistakes around position 3:\n",
      "[17:44:45] InvalidSMILES123\n",
      "[17:44:45] ~~^\n",
      "[17:44:45] SMILES Parse Error: Failed parsing SMILES 'InvalidSMILES123' for input: 'InvalidSMILES123'\n",
      "[17:44:45] SMILES Parse Error: syntax error while parsing: NaCl\n",
      "[17:44:45] SMILES Parse Error: check for mistakes around position 2:\n",
      "[17:44:45] NaCl\n",
      "[17:44:45] ~^\n",
      "[17:44:45] SMILES Parse Error: Failed parsing SMILES 'NaCl' for input: 'NaCl'\n",
      "[17:44:45] SMILES Parse Error: syntax error while parsing: InvalidSMILES123\n",
      "[17:44:45] SMILES Parse Error: check for mistakes around position 3:\n",
      "[17:44:45] InvalidSMILES123\n",
      "[17:44:45] ~~^\n",
      "[17:44:45] SMILES Parse Error: Failed parsing SMILES 'InvalidSMILES123' for input: 'InvalidSMILES123'\n",
      "[17:44:45] SMILES Parse Error: syntax error while parsing: NaCl\n",
      "[17:44:45] SMILES Parse Error: check for mistakes around position 2:\n",
      "[17:44:45] NaCl\n",
      "[17:44:45] ~^\n",
      "[17:44:45] SMILES Parse Error: Failed parsing SMILES 'NaCl' for input: 'NaCl'\n",
      "[17:44:45] SMILES Parse Error: syntax error while parsing: InvalidSMILES123\n",
      "[17:44:45] SMILES Parse Error: check for mistakes around position 3:\n",
      "[17:44:45] InvalidSMILES123\n",
      "[17:44:45] ~~^\n",
      "[17:44:45] SMILES Parse Error: Failed parsing SMILES 'InvalidSMILES123' for input: 'InvalidSMILES123'\n",
      "[17:44:45] SMILES Parse Error: syntax error while parsing: NaCl\n",
      "[17:44:45] SMILES Parse Error: check for mistakes around position 2:\n",
      "[17:44:45] NaCl\n",
      "[17:44:45] ~^\n",
      "[17:44:45] SMILES Parse Error: Failed parsing SMILES 'NaCl' for input: 'NaCl'\n",
      "[17:44:45] SMILES Parse Error: syntax error while parsing: InvalidSMILES123\n",
      "[17:44:45] SMILES Parse Error: check for mistakes around position 3:\n",
      "[17:44:45] InvalidSMILES123\n",
      "[17:44:45] ~~^\n",
      "[17:44:45] SMILES Parse Error: Failed parsing SMILES 'InvalidSMILES123' for input: 'InvalidSMILES123'\n",
      "[17:44:45] SMILES Parse Error: syntax error while parsing: NaCl\n",
      "[17:44:45] SMILES Parse Error: check for mistakes around position 2:\n",
      "[17:44:45] NaCl\n",
      "[17:44:45] ~^\n",
      "[17:44:45] SMILES Parse Error: Failed parsing SMILES 'NaCl' for input: 'NaCl'\n",
      "[17:44:45] SMILES Parse Error: syntax error while parsing: InvalidSMILES123\n",
      "[17:44:45] SMILES Parse Error: check for mistakes around position 3:\n",
      "[17:44:45] InvalidSMILES123\n",
      "[17:44:45] ~~^\n",
      "[17:44:45] SMILES Parse Error: Failed parsing SMILES 'InvalidSMILES123' for input: 'InvalidSMILES123'\n",
      "[17:44:45] SMILES Parse Error: syntax error while parsing: NaCl\n",
      "[17:44:45] SMILES Parse Error: check for mistakes around position 2:\n",
      "[17:44:45] NaCl\n",
      "[17:44:45] ~^\n",
      "[17:44:45] SMILES Parse Error: Failed parsing SMILES 'NaCl' for input: 'NaCl'\n",
      "[17:44:45] SMILES Parse Error: syntax error while parsing: InvalidSMILES123\n",
      "[17:44:45] SMILES Parse Error: check for mistakes around position 3:\n",
      "[17:44:45] InvalidSMILES123\n",
      "[17:44:45] ~~^\n",
      "[17:44:45] SMILES Parse Error: Failed parsing SMILES 'InvalidSMILES123' for input: 'InvalidSMILES123'\n",
      "[17:44:45] SMILES Parse Error: syntax error while parsing: NaCl\n",
      "[17:44:45] SMILES Parse Error: check for mistakes around position 2:\n",
      "[17:44:45] NaCl\n",
      "[17:44:45] ~^\n",
      "[17:44:45] SMILES Parse Error: Failed parsing SMILES 'NaCl' for input: 'NaCl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "import numpy as np\n",
    "\n",
    "# Generate a list of SMILES (valid and a few invalid)\n",
    "smiles_list = [\n",
    "    \"CCO\", \"O=C(O)c1ccccc1OC\", \"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\", \n",
    "    \"C([C@@H]([C@@H]([C@H](O)CO)O)O)O\", \"CC(=O)OC1=CC=CC=C1C(=O)O\",\n",
    "    \"CC(C)CC1=CC=C(C=C1)O\", \"C1=CC=C(C=C1)O\", \"C1CCCCC1\", \n",
    "    \"C1=CC=NC(=C1)N\", \"C(CO)NC(C)C\", \"InvalidSMILES123\", \n",
    "    \"C1CCOC1\", \"C1=CN=C2C(=N1)C=NC=N2\", \"NaCl\", \n",
    "    # ... You can add more SMILES. ...\n",
    "]\n",
    "\n",
    "# Generate synthetic solubility based on descriptors\n",
    "data = []\n",
    "for smiles in smiles_list * 10:  # Repeat to create more entries.\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        # Calculate descriptors\n",
    "        logp = Descriptors.MolLogP(mol)\n",
    "        mol_wt = Descriptors.MolWt(mol)\n",
    "        h_bond_donors = Descriptors.NumHDonors(mol)\n",
    "        \n",
    "        # Simulate solubility: higher solubility for lower logP, lower molecular weight\n",
    "        solubility = 0.5 - 0.02 * logp + 0.001 * mol_wt - 0.1 * h_bond_donors\n",
    "        solubility += np.random.normal(0, 0.05)  # Add noise\n",
    "        \n",
    "        # Normalize: Clip solubility between 0 and 1\n",
    "        solubility = np.clip(solubility, 0.05, 0.95)\n",
    "        data.append({\"SMILES\": smiles, \"Solubility\": round(solubility, 2)})\n",
    "\n",
    "# Create DataFrame and save\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"sample_solubility_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare the data and calculate descriptions\n",
    "The amount of features we import in our file has great impact. \n",
    "Too much features without PCA leads to overfitting. This is what I saw when I imported 3d data in current code.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do we have outliers?\n",
    "If the output of the following cell shows many outliers, Robust Scaling is the best choice for normalizing. Otherwise, use Standard Scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of outliers per column: MinAbsEStateIndex         10\n",
      "SPS                       30\n",
      "MinPartialCharge          10\n",
      "MaxAbsPartialCharge       10\n",
      "FpDensityMorgan1          10\n",
      "                          ..\n",
      "fr_para_hydroxylation     30\n",
      "fr_phenol                 20\n",
      "fr_phenol_noOrthoHbond    20\n",
      "fr_pyridine               10\n",
      "Solubility                10\n",
      "Length: 81, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"molecular_descriptors.csv\")\n",
    "\n",
    "# Exclude non-numeric columns (e.g., SMILES, Solubility)\n",
    "numeric_data = data.select_dtypes(include=[np.number])\n",
    "\n",
    "# Detect outliers using IQR\n",
    "Q1 = numeric_data.quantile(0.25)\n",
    "Q3 = numeric_data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Identify outliers\n",
    "outliers = ((numeric_data < (Q1 - 1.5 * IQR)) | (numeric_data > (Q3 + 1.5 * IQR))).sum()\n",
    "\n",
    "# Print the number of outliers per column\n",
    "print(f\"the number of outliers per column: {outliers[outliers > 0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid molecules: 120\n",
      "Saved descriptors to molecular_descriptors.csv\n"
     ]
    }
   ],
   "source": [
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"sample_solubility_2.csv\")\n",
    "\n",
    "def get_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        desc = Descriptors.CalcMolDescriptors(mol)\n",
    "        desc[\"PolarSurfaceArea\"] = rdMolDescriptors.CalcTPSA(mol)  # 2D Descriptor\n",
    "\n",
    "        # Generate 3D Conformer (required for 3D descriptors)\n",
    "        mol = Chem.AddHs(mol)  # Add hydrogens\n",
    "        if AllChem.EmbedMolecule(mol, AllChem.ETKDG()) == 0:  # Ensure embedding succeeds\n",
    "            desc[\"RadiusOfGyration\"] = rdMolDescriptors.CalcRadiusOfGyration(mol)  # 3D Descriptor\n",
    "            desc[\"Asphericity\"] = rdMolDescriptors.CalcAsphericity(mol)  # 3D Descriptor\n",
    "            desc[\"Eccentricity\"] = rdMolDescriptors.CalcEccentricity(mol)  # 3D Descriptor\n",
    "        else:\n",
    "            desc[\"RadiusOfGyration\"] = None\n",
    "            desc[\"Asphericity\"] = None\n",
    "            desc[\"Eccentricity\"] = None\n",
    "\n",
    "        return desc\n",
    "    return None\n",
    "\n",
    "# Apply the function to create a descriptor DataFrame\n",
    "descriptor_list = []\n",
    "for idx, row in data.iterrows():\n",
    "    desc = get_descriptors(row[\"SMILES\"])\n",
    "    if desc is not None:\n",
    "        desc[\"SMILES\"] = row[\"SMILES\"]  # Track valid SMILES\n",
    "        desc[\"Solubility\"] = row[\"Solubility\"]\n",
    "        descriptor_list.append(desc)\n",
    "\n",
    "# Create final DataFrame\n",
    "df = pd.DataFrame(descriptor_list).dropna()\n",
    "print(f\"Valid molecules: {len(df)}\")\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"molecular_descriptors.csv\", index=False)\n",
    "print(\"Saved descriptors to molecular_descriptors.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess    \n",
    "Main parts:  \n",
    "1. Split\n",
    "2. Normalize (if didn't in previous part)  \n",
    "Had major problams with this part.  \n",
    "\n",
    "\n",
    "The changes I can make to improve my results:    \n",
    "- remove ouliers: Didn't work well with my sample.  \n",
    "- Selecting best features while omitting others to avoid overfitting. I have to recieve the name of selected features.  \n",
    "- Handle missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your generated descriptor data\n",
    "df = pd.read_csv(\"molecular_descriptors.csv\")\n",
    "\n",
    "# Split into features (X) and target (y)\n",
    "X = df.drop([\"SMILES\", \"Solubility\"], axis=1)\n",
    "y = df[\"Solubility\"]\n",
    "\n",
    "# Handle missing values (if any)\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Split into train/test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train = (96, 221) , X_test = (24, 221), y_train = (96,), y_test = (24,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train = {X_train.shape} , X_test = {X_test.shape}, y_train = {y_train.shape}, y_test = {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled = (96, 221) , X_test_scaled = (24, 221)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the data with RobustScaler as we have outliers.\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data (if applicable)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Check the scaling\n",
    "print(f\"X_train_scaled = {X_train_scaled.shape} , X_test_scaled = {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96, 221), (96, 17))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Decreasing the number of features from 221 to the best number of components:\n",
    "pca = PCA(n_components=17)\n",
    "pca.fit(X_train_scaled)\n",
    "\n",
    "X_new_train= pca.transform(X_train_scaled)\n",
    "X_new_test = pca.transform(X_test_scaled)\n",
    "#y_new_train = y_train_clean\n",
    "X_train.shape , X_new_train.shape, #y_new_train.shape\n",
    "#Check the decrease in features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's learn more about the features our model used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names loaded from CSV: ['MaxAbsEStateIndex', 'MaxEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', 'MolWt', 'HeavyAtomMolWt', 'ExactMolWt', 'NumValenceElectrons', 'NumRadicalElectrons', 'MaxPartialCharge', 'MinPartialCharge', 'MaxAbsPartialCharge', 'MinAbsPartialCharge', 'FpDensityMorgan1', 'FpDensityMorgan2', 'FpDensityMorgan3', 'BCUT2D_MWHI', 'BCUT2D_MWLOW', 'BCUT2D_CHGHI', 'BCUT2D_CHGLO', 'BCUT2D_LOGPHI', 'BCUT2D_LOGPLOW', 'BCUT2D_MRHI', 'BCUT2D_MRLOW', 'AvgIpc', 'BalabanJ', 'BertzCT', 'Chi0', 'Chi0n', 'Chi0v', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3n', 'Chi3v', 'Chi4n', 'Chi4v', 'HallKierAlpha', 'Ipc', 'Kappa1', 'Kappa2', 'Kappa3', 'LabuteASA', 'PEOE_VSA1', 'PEOE_VSA10', 'PEOE_VSA11', 'PEOE_VSA12', 'PEOE_VSA13', 'PEOE_VSA14', 'PEOE_VSA2', 'PEOE_VSA3', 'PEOE_VSA4', 'PEOE_VSA5', 'PEOE_VSA6', 'PEOE_VSA7', 'PEOE_VSA8', 'PEOE_VSA9', 'SMR_VSA1', 'SMR_VSA10', 'SMR_VSA2', 'SMR_VSA3', 'SMR_VSA4', 'SMR_VSA5', 'SMR_VSA6', 'SMR_VSA7', 'SMR_VSA8', 'SMR_VSA9', 'SlogP_VSA1', 'SlogP_VSA10', 'SlogP_VSA11', 'SlogP_VSA12', 'SlogP_VSA2', 'SlogP_VSA3', 'SlogP_VSA4', 'SlogP_VSA5', 'SlogP_VSA6', 'SlogP_VSA7', 'SlogP_VSA8', 'SlogP_VSA9', 'TPSA', 'EState_VSA1', 'EState_VSA10', 'EState_VSA11', 'EState_VSA2', 'EState_VSA3', 'EState_VSA4', 'EState_VSA5', 'EState_VSA6', 'EState_VSA7', 'EState_VSA8', 'EState_VSA9', 'VSA_EState1', 'VSA_EState10', 'VSA_EState2', 'VSA_EState3', 'VSA_EState4', 'VSA_EState5', 'VSA_EState6', 'VSA_EState7', 'VSA_EState8', 'VSA_EState9', 'FractionCSP3', 'HeavyAtomCount', 'NHOHCount', 'NOCount', 'NumAliphaticCarbocycles', 'NumAliphaticHeterocycles', 'NumAliphaticRings', 'NumAmideBonds', 'NumAromaticCarbocycles', 'NumAromaticHeterocycles', 'NumAromaticRings', 'NumAtomStereoCenters', 'NumBridgeheadAtoms', 'NumHAcceptors', 'NumHDonors', 'NumHeteroatoms', 'NumHeterocycles', 'NumRotatableBonds', 'NumSaturatedCarbocycles', 'NumSaturatedHeterocycles', 'NumSaturatedRings', 'NumSpiroAtoms', 'NumUnspecifiedAtomStereoCenters', 'Phi', 'RingCount', 'MolLogP', 'MolMR', 'fr_Al_COO', 'fr_Al_OH', 'fr_Al_OH_noTert', 'fr_ArN', 'fr_Ar_COO', 'fr_Ar_N', 'fr_Ar_NH', 'fr_Ar_OH', 'fr_COO', 'fr_COO2', 'fr_C_O', 'fr_C_O_noCOO', 'fr_C_S', 'fr_HOCCN', 'fr_Imine', 'fr_NH0', 'fr_NH1', 'fr_NH2', 'fr_N_O', 'fr_Ndealkylation1', 'fr_Ndealkylation2', 'fr_Nhpyrrole', 'fr_SH', 'fr_aldehyde', 'fr_alkyl_carbamate', 'fr_alkyl_halide', 'fr_allylic_oxid', 'fr_amide', 'fr_amidine', 'fr_aniline', 'fr_aryl_methyl', 'fr_azide', 'fr_azo', 'fr_barbitur', 'fr_benzene', 'fr_benzodiazepine', 'fr_bicyclic', 'fr_diazo', 'fr_dihydropyridine', 'fr_epoxide', 'fr_ester', 'fr_ether', 'fr_furan', 'fr_guanido', 'fr_halogen', 'fr_hdrzine', 'fr_hdrzone', 'fr_imidazole', 'fr_imide', 'fr_isocyan', 'fr_isothiocyan', 'fr_ketone', 'fr_ketone_Topliss', 'fr_lactam', 'fr_lactone', 'fr_methoxy', 'fr_morpholine', 'fr_nitrile', 'fr_nitro', 'fr_nitro_arom', 'fr_nitro_arom_nonortho', 'fr_nitroso', 'fr_oxazole', 'fr_oxime', 'fr_para_hydroxylation', 'fr_phenol', 'fr_phenol_noOrthoHbond', 'fr_phos_acid', 'fr_phos_ester', 'fr_piperdine', 'fr_piperzine', 'fr_priamide', 'fr_prisulfonamd', 'fr_pyridine', 'fr_quatN', 'fr_sulfide', 'fr_sulfonamd', 'fr_sulfone', 'fr_term_acetylene', 'fr_tetrazole', 'fr_thiazole', 'fr_thiocyan', 'fr_thiophene', 'fr_unbrch_alkane', 'fr_urea', 'PolarSurfaceArea', 'RadiusOfGyration', 'Asphericity', 'Eccentricity']\n",
      "Number of features: 221\n"
     ]
    }
   ],
   "source": [
    "# Load feature names from molecular_description.csv\n",
    "file_path = \"molecular_descriptors.csv\"  \n",
    "molecular_data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract feature names from the CSV file\n",
    "feature_names = molecular_data.columns[:-2].tolist()  # Exclude the last two columns\n",
    "print(\"Feature names loaded from CSV:\", feature_names)\n",
    "print(\"Number of features:\", len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC1: ['EState_VSA9', 'EState_VSA1', 'SMR_VSA4', 'SlogP_VSA8', 'PEOE_VSA2']\n",
      "PC2: ['VSA_EState4', 'SMR_VSA4', 'PEOE_VSA2', 'EState_VSA1', 'EState_VSA10']\n",
      "PC3: ['VSA_EState4', 'EState_VSA9', 'EState_VSA1', 'SMR_VSA4', 'SlogP_VSA10']\n",
      "PC4: ['PEOE_VSA14', 'EState_VSA10', 'SlogP_VSA8', 'BCUT2D_MWHI', 'PEOE_VSA11']\n",
      "PC5: ['SMR_VSA4', 'BCUT2D_MWHI', 'PEOE_VSA14', 'EState_VSA1', 'VSA_EState5']\n",
      "PC6: ['BCUT2D_MWHI', 'SlogP_VSA8', 'SMR_VSA4', 'SlogP_VSA4', 'BCUT2D_LOGPHI']\n",
      "PC7: ['PEOE_VSA2', 'SlogP_VSA8', 'SlogP_VSA4', 'EState_VSA8', 'SMR_VSA4']\n",
      "PC8: ['Kappa3', 'EState_VSA8', 'VSA_EState8', 'Phi', 'EState_VSA9']\n",
      "PC9: ['EState_VSA4', 'BCUT2D_MWHI', 'VSA_EState8', 'Eccentricity', 'BalabanJ']\n",
      "PC10: ['SlogP_VSA4', 'EState_VSA1', 'EState_VSA9', 'VSA_EState9', 'BalabanJ']\n",
      "PC11: ['PEOE_VSA2', 'EState_VSA9', 'BalabanJ', 'FpDensityMorgan1', 'SlogP_VSA4']\n",
      "PC12: ['Asphericity', 'Eccentricity', 'RadiusOfGyration', 'SlogP_VSA4', 'EState_VSA4']\n",
      "PC13: ['Eccentricity', 'Asphericity', 'RadiusOfGyration', 'EState_VSA4', 'MinAbsEStateIndex']\n",
      "PC14: ['RadiusOfGyration', 'Asphericity', 'Eccentricity', 'EState_VSA8', 'BalabanJ']\n",
      "PC15: ['MinAbsPartialCharge', 'MinAbsEStateIndex', 'MaxAbsEStateIndex', 'MinEStateIndex', 'MaxEStateIndex']\n",
      "PC16: ['MinEStateIndex', 'FpDensityMorgan1', 'qed', 'MaxEStateIndex', 'MinAbsPartialCharge']\n",
      "PC17: ['MinAbsEStateIndex', 'MinEStateIndex', 'FpDensityMorgan1', 'MinAbsPartialCharge', 'MolWt']\n"
     ]
    }
   ],
   "source": [
    "def get_pca_top_features(pca, feature_names, top_n=17):\n",
    "    \"\"\"\n",
    "    Get the top contributing features for each principal component.\n",
    "\n",
    "    Args:\n",
    "        pca: The trained PCA object.\n",
    "        feature_names: List of original feature names.\n",
    "        top_n: Number of top features to select for each principal component.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary where keys are principal components (PC1, PC2, ...) and values are lists of top features.\n",
    "    \"\"\"\n",
    "    # Create a DataFrame for PCA components\n",
    "    components = pd.DataFrame(\n",
    "        pca.components_,\n",
    "        columns=feature_names,\n",
    "        index=[f\"PC{i+1}\" for i in range(pca.n_components_)]\n",
    "    )\n",
    "    \n",
    "    # Find the top contributing features for each principal component\n",
    "    top_features = {}\n",
    "    for pc in components.index:\n",
    "        # Get the absolute values of contributions and sort them\n",
    "        sorted_features = components.loc[pc].abs().sort_values(ascending=False)\n",
    "        # Select the top N features\n",
    "        top_features[pc] = sorted_features.head(top_n).index.tolist()\n",
    "    \n",
    "    return top_features\n",
    "\n",
    "# Print the top features for each principal component\n",
    "top_features = get_pca_top_features(pca, feature_names, top_n=5)\n",
    "\n",
    "for pc, features in top_features.items():\n",
    "    print(f\"{pc}: {features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the model\n",
    "I used GridSearchCV to optimize the parameters of my randomforest model."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid:\n",
    "# If it took so long to run, you can reduce the number of parameters.\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_features': ['sqrt', 0.5]\n",
    "}\n",
    "\n",
    "# Initialize and fit grid search\n",
    "model = RandomForestRegressor(random_state=0)\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='neg_root_mean_squared_error', error_score='raise')\n",
    "grid_search.fit(X_new_train, y_train)\n",
    "\n",
    "# Get best model\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Now use best_model for predictions\n",
    "best_model.fit(X_new_train, y_train)\n",
    "\n",
    "# Predict solubilities\n",
    "y_pred_train_rf = best_model.predict(X_new_train)\n",
    "y_pred_test_rf = best_model.predict(X_new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load the model\n",
    "Why Save the Model?\n",
    "- **Consistency**: Saving the model ensures that you can reuse the same trained model without retraining, which avoids variations in results due to randomness.  \n",
    "\n",
    "\n",
    "- **Efficiency**: Loading a saved model is faster than retraining it every time."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Save the best model\n",
    "import joblib\n",
    "\n",
    "joblib.dump(best_model, \"best_model.pkl\")\n",
    "print(\"Model saved as best_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "best_model = joblib.load(\"best_model.pkl\")\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's spice up with testing other models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_new_train, y_train)\n",
    "\n",
    "y_pred_train_lr = model_lr.predict(X_new_train)\n",
    "y_pred_test_lr = model_lr.predict(X_new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model_dt = DecisionTreeRegressor(random_state=42)\n",
    "model_dt.fit(X_new_train, y_train)\n",
    "\n",
    "y_pred_train_dt = model_dt.predict(X_new_train)\n",
    "y_pred_test_dt = model_dt.predict(X_new_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "model_knn = KNeighborsRegressor(n_neighbors=8)\n",
    "model_knn.fit(X_new_train, y_train)\n",
    "\n",
    "y_pred_train_knn = model_knn.predict(X_new_train)\n",
    "y_pred_test_knn = model_knn.predict(X_new_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "model_gb = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "model_gb.fit(X_new_train, y_train)\n",
    "y_pred_train_gb = model_gb.predict(X_new_train)\n",
    "y_pred_test_gb = model_gb.predict(X_new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "model_svr = SVR()\n",
    "model_svr.fit(X_new_train, y_train)\n",
    "y_pred_train_svr = model_svr.predict(X_new_train)\n",
    "y_pred_test_svr = model_svr.predict(X_new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Case of running into bugs, Check these cells. Oherwise skip them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "#Verify Data Types\n",
    "print(y_train.dtype)  # Should output `float64` or `int64`\n",
    "print(y_test.dtype)   # Should not output `object`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))  # If it's a DataFrame, use .values. If it's an array, skip.\n",
    "\n",
    "# .values:\n",
    "#Ensure Input Shapes\n",
    "# Check that X_train, X_test, y_train, and y_test are NumPy arrays or Pandas DataFrames (not lists or other objects):\n",
    "# Convert to NumPy arrays if needed\n",
    "#X_train = X_train.values\n",
    "#X_test = X_test.values\n",
    "#y_train = y_train.values.ravel()  # Flatten to 1D array\n",
    "#y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RMSE (Root Mean Squared Error): Measures the average prediction error (lower = better).  \n",
    "Example: RMSE = 0.5 means predictions are off by ~0.5 units (e.g., logS) on average.<br>\n",
    "<br> \n",
    "\n",
    "- R² (R-squared): Measures how much variance your model explains (1 = perfect, 0 = no better than the mean). <br>Train R² ≈ Test R² (e.g., Train R² = 0.85, Test R² = 0.80). Test R² ≥ 0.7 is often good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I define a function to find these metrics easier later.\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Let's define a function that works for testing each regression model.\n",
    "def calculate_regression_metrics(y_train, y_test, y_pred_train, y_pred_test):\n",
    "    # Calculate metrics for training set\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    rmse_train = np.sqrt(mse_train)  # Compute RMSE manually\n",
    "    #rmse_train = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    \n",
    "    # Calculate metrics for test set\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    rmse_test = np.sqrt(mse_test)  # Compute RMSE manually\n",
    "    #rmse_test = mean_squared_error(y_test, y_pred_test, squared=False)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    print(f\"Train RMSE: {rmse_train:.2f}, Train R²: {r2_train:.2f}\")\n",
    "    print(f\"Test RMSE: {rmse_test:.2f}, Test R²: {r2_test:.2f}\")\n",
    "\n",
    "    return rmse_train, rmse_test, r2_train, r2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔷 Random Forest Regressor\n",
      "Best Parameters: {'max_depth': 20, 'max_features': 0.5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Train RMSE: 0.06, Train R²: 0.80\n",
      "Test RMSE: 0.06, Test R²: 0.63\n",
      "\n",
      "🔷 Linear Regression\n",
      "Train RMSE: 0.05, Train R²: 0.86\n",
      "Test RMSE: 0.06, Test R²: 0.62\n",
      "\n",
      "🔷 Decision Tree Regressor\n",
      "Train RMSE: 0.00, Train R²: 1.00\n",
      "Test RMSE: 0.07, Test R²: 0.44\n",
      "\n",
      "🔷 Gradient Boosting Regressor\n",
      "Train RMSE: 0.01, Train R²: 0.99\n",
      "Test RMSE: 0.06, Test R²: 0.57\n",
      "\n",
      "🔷 Support Vector Regressor\n",
      "Train RMSE: 0.05, Train R²: 0.83\n",
      "Test RMSE: 0.08, Test R²: 0.41\n",
      "\n",
      "🔷 K-Nearest Neighbors Regressor\n",
      "Train RMSE: 0.05, Train R²: 0.85\n",
      "Test RMSE: 0.06, Test R²: 0.61\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Random Forest Regressor\n",
    "print(\"🔷 Random Forest Regressor\")\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "train_rmse_rf, test_rmse_rf, train_r2_rf, test_r2_rf = calculate_regression_metrics(\n",
    "    y_train, y_test, y_pred_train_rf, y_pred_test_rf\n",
    ")\n",
    "\n",
    "# Evaluate Linear Regression\n",
    "print(\"\\n🔷 Linear Regression\")\n",
    "train_rmse_lr, test_rmse_lr, train_r2_lr, test_r2_lr = calculate_regression_metrics(\n",
    "    y_train, y_test, y_pred_train_lr, y_pred_test_lr\n",
    ")\n",
    "\n",
    "# Evaluate Decision Tree Regressor\n",
    "print(\"\\n🔷 Decision Tree Regressor\")\n",
    "train_rmse_dt, test_rmse_dt, train_r2_dt, test_r2_dt = calculate_regression_metrics(\n",
    "    y_train, y_test, y_pred_train_dt, y_pred_test_dt\n",
    ")\n",
    "\n",
    "# Evaluate Gradient Boosting Regressor\n",
    "print(\"\\n🔷 Gradient Boosting Regressor\")\n",
    "train_rmse_gb, test_rmse_gb, train_r2_gb, test_r2_gb = calculate_regression_metrics(\n",
    "    y_train, y_test, y_pred_train_gb, y_pred_test_gb\n",
    ")\n",
    "\n",
    "# Evaluate Support Vector Regressor\n",
    "print(\"\\n🔷 Support Vector Regressor\")\n",
    "train_rmse_svr, test_rmse_svr, train_r2_svr, test_r2_svr = calculate_regression_metrics(\n",
    "    y_train, y_test, y_pred_train_svr, y_pred_test_svr\n",
    ")\n",
    "\n",
    "# Evaluate K-Nearest Neighbors Regressor\n",
    "print(\"\\n🔷 K-Nearest Neighbors Regressor\")\n",
    "train_rmse_knn, test_rmse_knn, train_r2_knn, test_r2_knn = calculate_regression_metrics(\n",
    "    y_train, y_test, y_pred_train_knn, y_pred_test_knn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare test R2 on a plot:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "r2_test = [test_r2_rf, test_r2_dt, test_r2_lr, test_r2_gb, test_r2_svr, test_r2_knn]\n",
    "\n",
    "title = ['RF', 'DT', 'LR', 'GB', 'SVR', 'KNN']\n",
    "\n",
    "colors = ['red', 'blue', 'green', 'gray', 'purple', 'yellow']\n",
    "\n",
    "plt.bar(title, r2_test, color=colors)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Evaluation shows that this model is not efficient enough. It might be due small sample size or inapropriate ML algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check a random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 5\n",
      "Real Label: 0.67\n",
      "Predicted Label: 0.4974493406593403\n"
     ]
    }
   ],
   "source": [
    "# Specify the index of the data point you want to check\n",
    "specific_index = 5  # Replace with the desired index\n",
    "\n",
    "# Ensure X_test and y_test are NumPy arrays\n",
    "X_test_array = np.array(X_new_test)  # Convert to NumPy array if it's a DataFrame\n",
    "y_test_array = np.array(y_test)  # Convert to NumPy array if it's a Series\n",
    "\n",
    "# Get the data point and its true label\n",
    "data_point = X_test_array[specific_index].reshape(1, -1)  # Reshape for prediction\n",
    "real_label = y_test_array[specific_index]\n",
    "\n",
    "# Predict the label using the model\n",
    "predicted_label = best_model.predict(data_point)[0]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Index: {specific_index}\")\n",
    "print(f\"Real Label: {real_label}\")\n",
    "print(f\"Predicted Label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can change the number of PCA components(features) if the model is overfitting.\n",
    "1. Use the number you recieve as number of PCA components in the following cell in the pca = PCA(n_components=17)\n",
    "2. Run the model and Evaluate again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of PCA components: 19\n"
     ]
    }
   ],
   "source": [
    "# Finding the best number of PCA components(features).\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "best_score = -1\n",
    "for n in range(5, 21):  # Test PCA components from 5 to 20\n",
    "    pca = PCA(n_components=n)\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    scores = cross_val_score(model, X_train_pca, y_train, cv=5, scoring='r2')\n",
    "    if scores.mean() > best_score:\n",
    "        best_score = scores.mean()\n",
    "        best_n = n\n",
    "\n",
    "print(f\"Best number of PCA components: {best_n}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
