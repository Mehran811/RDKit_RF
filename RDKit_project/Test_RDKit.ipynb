{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test _ Solubility Prediction by Random Forest Algorithem Using RDKit 2D and 3D Descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid molecules: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:19:36] SMILES Parse Error: unclosed ring for input: 'C1=CC=C(C=C1)NO2'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"sample_solubility.csv\")\n",
    "\n",
    "# Function to convert SMILES to molecules and calculate descriptors\n",
    "def get_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        # Calculate descriptors (returns a dictionary)\n",
    "        descriptors = Descriptors.CalcMolDescriptors(mol)\n",
    "        return descriptors\n",
    "    else:\n",
    "        return None  # Skip invalid SMILES\n",
    "\n",
    "# Apply the function to create a descriptor DataFrame\n",
    "descriptor_list = []\n",
    "for idx, row in data.iterrows():\n",
    "    desc = get_descriptors(row[\"SMILES\"])\n",
    "    if desc is not None:\n",
    "        desc[\"SMILES\"] = row[\"SMILES\"]  # Track valid SMILES\n",
    "        desc[\"Solubility\"] = row[\"Solubility\"]\n",
    "        descriptor_list.append(desc)\n",
    "\n",
    "# Create final DataFrame\n",
    "df = pd.DataFrame(descriptor_list).dropna()\n",
    "print(f\"Valid molecules: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What Happens:\n",
    "Invalid SMILES (e.g., NaCl) are skipped.\n",
    "Descriptors like MolLogP, MolWt, and NumHAcceptors are calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My other failed trys:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "### Load the dataset\n",
    "data = pd.read_csv(\"sample_solubility_2.csv\")\n",
    "\n",
    "### Function to convert SMILES to molecules and calculate descriptors\n",
    "def get_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        # Calculate descriptors (returns a dictionary)\n",
    "        descriptors = Descriptors.CalcMolDescriptors(mol)\n",
    "        return descriptors\n",
    "    else:\n",
    "        return None  # Skip invalid SMILES\n",
    "\n",
    "### Apply the function to create a descriptor DataFrame\n",
    "descriptor_list = []\n",
    "for idx, row in data.iterrows():\n",
    "    desc = get_descriptors(row[\"SMILES\"])\n",
    "    if desc is not None:\n",
    "        desc[\"SMILES\"] = row[\"SMILES\"]  # Track valid SMILES\n",
    "        desc[\"Solubility\"] = row[\"Solubility\"]\n",
    "        descriptor_list.append(desc)\n",
    "\n",
    "### Create final DataFrame\n",
    "df = pd.DataFrame(descriptor_list).dropna()\n",
    "print(f\"Valid molecules: {len(df)}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "This code gave me better test R2. However the current code improved my train R2 with increasing features.\n",
    "\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "\n",
    "### Load the dataset\n",
    "data = pd.read_csv(\"sample_solubility_2.csv\")\n",
    "\n",
    "def get_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        desc = Descriptors.CalcMolDescriptors(mol)\n",
    "        # Corrected Polar Surface Area Calculation\n",
    "        desc[\"PolarSurfaceArea\"] = rdMolDescriptors.CalcTPSA(mol)\n",
    "        return desc\n",
    "    return None\n",
    "\n",
    "### Apply the function to create a descriptor DataFrame\n",
    "descriptor_list = []\n",
    "for idx, row in data.iterrows():\n",
    "    desc = get_descriptors(row[\"SMILES\"])\n",
    "    if desc is not None:\n",
    "        desc[\"SMILES\"] = row[\"SMILES\"]  # Track valid SMILES\n",
    "        desc[\"Solubility\"] = row[\"Solubility\"]\n",
    "        descriptor_list.append(desc)\n",
    "\n",
    "### Create final DataFrame\n",
    "df = pd.DataFrame(descriptor_list).dropna()\n",
    "print(f\"Valid molecules: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features (X) and target (y)\n",
    "X = df.drop([\"SMILES\", \"Solubility\"], axis=1)\n",
    "y = df[\"Solubility\"]\n",
    "\n",
    "# Handle missing values (if any)\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Split into train/test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'squared'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     45\u001b[39m y_pred_train = model.predict(X_train)\n\u001b[32m     46\u001b[39m y_pred_test = model.predict(X_test)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTrain RMSE:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[32m     49\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTest RMSE:\u001b[39m\u001b[33m\"\u001b[39m, mean_squared_error(y_test, y_pred_test, squared=\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m     50\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTest RÂ²:\u001b[39m\u001b[33m\"\u001b[39m, r2_score(y_test, y_pred_test))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:194\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    191\u001b[39m func_sig = signature(func)\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m params = \u001b[43mfunc_sig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m params.apply_defaults()\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\miniconda3\\Lib\\inspect.py:3277\u001b[39m, in \u001b[36mSignature.bind\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m   3273\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[32m   3274\u001b[39m \u001b[33;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[32m   3275\u001b[39m \u001b[33;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[32m   3276\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\miniconda3\\Lib\\inspect.py:3266\u001b[39m, in \u001b[36mSignature._bind\u001b[39m\u001b[34m(self, args, kwargs, partial)\u001b[39m\n\u001b[32m   3256\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   3257\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mgot some positional-only arguments passed as \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   3258\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mkeyword arguments: \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m   (...)\u001b[39m\u001b[32m   3263\u001b[39m             ),\n\u001b[32m   3264\u001b[39m         )\n\u001b[32m   3265\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3266\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   3267\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m   3268\u001b[39m                 arg=\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[32m   3270\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_arguments_cls(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "\u001b[31mTypeError\u001b[39m: got an unexpected keyword argument 'squared'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"sample_solubility_2.csv\")\n",
    "df[\"Solubility\"] = pd.to_numeric(df[\"Solubility\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"Solubility\"])\n",
    "\n",
    "# Calculate descriptors\n",
    "def get_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        return Descriptors.CalcMolDescriptors(mol)\n",
    "    return None\n",
    "\n",
    "descriptor_list = []\n",
    "for idx, row in df.iterrows():\n",
    "    desc = get_descriptors(row[\"SMILES\"])\n",
    "    if desc is not None:\n",
    "        desc[\"Solubility\"] = row[\"Solubility\"]\n",
    "        descriptor_list.append(desc)\n",
    "\n",
    "df_clean = pd.DataFrame(descriptor_list).dropna()\n",
    "\n",
    "# Split data (X and y are DataFrames/Series)\n",
    "X = df_clean.drop(\"Solubility\", axis=1)\n",
    "y = df_clean[\"Solubility\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to NumPy arrays AFTER splitting\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values.ravel()  # Flatten to 1D\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Train model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "print(\"Train RMSE:\", mean_squared_error(y_train, y_pred_train, squared=False))\n",
    "print(\"Test RMSE:\", mean_squared_error(y_test, y_pred_test, squared=False))\n",
    "print(\"Test RÂ²:\", r2_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some advanced code to remove ouliers whitch didn't work well:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import PowerTransformer, RobustScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"molecular_descriptors.csv\")\n",
    "X = df.drop([\"SMILES\", \"Solubility\"], axis=1)\n",
    "y = df[\"Solubility\"]\n",
    "\n",
    "# 1. Initial Split (preserve data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Conservative Preprocessing\n",
    "preprocessor = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),  # Handle missing values\n",
    "    VarianceThreshold(threshold=0.1),  # Remove low-variance features\n",
    "    PowerTransformer(method=\"yeo-johnson\"),  # Make features more Gaussian\n",
    "    IsolationForest(contamination=0.05, random_state=42)  # Mild outlier detection\n",
    ")\n",
    "\n",
    "# 3. Fit on training data ONLY\n",
    "outlier_mask = preprocessor.fit_predict(X_train)\n",
    "\n",
    "# 4. Filter training data (keep inliers AND \"mild\" outliers)\n",
    "X_train_clean = X_train[outlier_mask == 1]\n",
    "y_train_clean = y_train[outlier_mask == 1]\n",
    "print(f\"Retained {len(X_train_clean)} samples after cleaning\")\n",
    "\n",
    "# 5. Final preprocessing for modeling\n",
    "final_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    PowerTransformer(),\n",
    "    RobustScaler()\n",
    ")\n",
    "\n",
    "X_train_preprocessed = final_transformer.fit_transform(X_train_clean)\n",
    "X_test_preprocessed = final_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from scipy import stats\n",
    "\n",
    "# Load your generated descriptor data\n",
    "df = pd.read_csv(\"molecular_descriptors.csv\")\n",
    "\n",
    "# 1. Split into features (X) and target (y)\n",
    "X = df.drop(columns=[\"Solubility\", \"SMILES\"])  # Remove target and identifier\n",
    "y = df[\"Solubility\"]\n",
    "feature_names = X.columns.tolist()  # Save original feature names\n",
    "\n",
    "# 2. Split into train/test sets FIRST (critical for valid preprocessing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 3. Handle missing values using training set statistics\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame to retain feature names\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed, columns=feature_names)\n",
    "X_test_imputed = pd.DataFrame(X_test_imputed, columns=feature_names)\n",
    "\n",
    "# 4. Remove outliers using Z-scores (applied only to training data)\n",
    "#z_scores = np.abs(stats.zscore(X_train_imputed))\n",
    "#outlier_mask = (z_scores < 3).all(axis=1)  # Keep rows where all features |Z| < 3\n",
    "\n",
    "#X_train_clean = X_train_imputed[outlier_mask]\n",
    "#y_train_clean = y_train[outlier_mask]\n",
    "#print(f\"Removed {len(X_train) - len(X_train_clean)} outliers\")\n",
    "\n",
    "# 5. Feature selection using cleaned training data\n",
    "selector = SelectKBest(score_func=f_regression, k=10)\n",
    "X_train_selected = selector.fit_transform(X_train_clean, y_train_clean)\n",
    "X_test_selected = selector.transform(X_test_imputed)\n",
    "\n",
    "# Get selected feature names\n",
    "selected_features = X_train_clean.columns[selector.get_support()]\n",
    "print(\"\\nSelected features:\", selected_features.tolist())\n",
    "\n",
    "# 6. Final data shapes\n",
    "print(\"\\nFinal shapes:\")\n",
    "print(f\"Training set: {X_train_selected.shape} (features), {y_train_clean.shape} (target)\")\n",
    "print(f\"Test set: {X_test_selected.shape} (features), {y_test.shape} (target)\")\n",
    "\n",
    "# Now ready for model training!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Split into features (X) and target (y)\n",
    "X = df.drop([\"SMILES\", \"Solubility\"], axis=1)\n",
    "y = df[\"Solubility\"]\n",
    "\n",
    "# Assuming X is a DataFrame (before splitting)\n",
    "feature_names = X.columns.tolist()  # Save column names here!\n",
    "\n",
    "# Handle missing values (if any)\n",
    "# Replace missing values using a descriptive statistic like median, mean or...\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Remove outliers:\n",
    "from scipy import stats  \n",
    "# Keep data within 3 standard deviations\n",
    "#df_clean = df_clean[(np.abs(stats.zscore(df_clean[\"Solubility\"])) < 3)]    \n",
    "\n",
    "# Split into train/test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Before feature selection\n",
    "print(\"Original X_train shape:\", X_train.shape)  # e.g., (800, 221)\n",
    "\n",
    "# Select features\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "selector = SelectKBest(f_regression, k=10)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)  # Output is NumPy array\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# After feature selection\n",
    "print(\"New X_train shape:\", X_train.shape)       # Should be (800, 10)\n",
    "print(\"New X_test shape:\", X_test.shape)         # Should be (200, 10)\n",
    "\n",
    "# Get selected feature NAMES\n",
    "selected_mask = selector.get_support()  # Boolean array of selected features\n",
    "selected_features = X_train.columns[selected_mask]  # Use X_train (DataFrame) columns\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# After outlier removal, use CLEANED TARGETS\n",
    "X_new_train = X_train_clean  # Your cleaned features (91 samples)\n",
    "y_new_train = y_train_clean  # Must use matching cleaned targets (91 samples)\n",
    "\n",
    "# Verify shapes match\n",
    "print(f\"X shape: {X_new_train.shape}, y shape: {y_new_train.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
