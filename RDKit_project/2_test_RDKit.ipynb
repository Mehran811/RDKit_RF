{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solubility Prediction by Random Forest and RDKit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogP, also known as the partition coefficient, measures a molecule's lipophilicity, or its affinity for a lipid (fat) environment versus a water environment. It's expressed as the logarithm of the ratio of the concentrations of the molecule in the two phases (typically octanol and water). A higher LogP value indicates greater lipophilicity, meaning the molecule is more soluble in fats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hydrogen bond donors are atoms or molecules that possess a hydrogen atom directly bonded to a more electronegative atom, such as oxygen (O), nitrogen (N), or fluorine (F). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "import numpy as np\n",
    "\n",
    "# Generate a list of SMILES (valid and a few invalid)\n",
    "smiles_list = [\n",
    "    \"CCO\", \"O=C(O)c1ccccc1OC\", \"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\", \n",
    "    \"C([C@@H]([C@@H]([C@H](O)CO)O)O)O\", \"CC(=O)OC1=CC=CC=C1C(=O)O\",\n",
    "    \"CC(C)CC1=CC=C(C=C1)O\", \"C1=CC=C(C=C1)O\", \"C1CCCCC1\", \n",
    "    \"C1=CC=NC(=C1)N\", \"C(CO)NC(C)C\", \"InvalidSMILES123\", \n",
    "    \"C1CCOC1\", \"C1=CN=C2C(=N1)C=NC=N2\", \"NaCl\", \n",
    "    # ... Add more SMILES (repeat with variations) ...\n",
    "]\n",
    "\n",
    "# Generate synthetic solubility based on descriptors\n",
    "data = []\n",
    "for smiles in smiles_list * 10:  # Repeat to create 200+ entries\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        # Calculate descriptors\n",
    "        logp = Descriptors.MolLogP(mol)\n",
    "        mol_wt = Descriptors.MolWt(mol)\n",
    "        h_bond_donors = Descriptors.NumHDonors(mol)\n",
    "        \n",
    "        # Simulate solubility: higher solubility for lower logP, lower molecular weight\n",
    "        solubility = 0.5 - 0.02 * logp + 0.001 * mol_wt - 0.1 * h_bond_donors\n",
    "        solubility += np.random.normal(0, 0.05)  # Add noise\n",
    "        \n",
    "        # Normalize: Clip solubility between 0 and 1\n",
    "        solubility = np.clip(solubility, 0.05, 0.95)\n",
    "        data.append({\"SMILES\": smiles, \"Solubility\": round(solubility, 2)})\n",
    "\n",
    "# Create DataFrame and save\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"sample_solubility_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare the data and calculate descriptions\n",
    "The amount of features we import in our file has great impact. \n",
    "Too much features without PCA leads to overfitting. This is what I saw when I imported 3d data in current code.  \n",
    "  \n",
    "  Warning: I didn't normalize new features. I should check them again.  \n",
    "  So I have 221 features with deifferent weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid molecules: 120\n",
      "Saved descriptors to molecular_descriptors.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"sample_solubility_2.csv\")\n",
    "\n",
    "def get_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        desc = Descriptors.CalcMolDescriptors(mol)\n",
    "        desc[\"PolarSurfaceArea\"] = rdMolDescriptors.CalcTPSA(mol)  # 2D Descriptor\n",
    "\n",
    "        # Generate 3D Conformer (required for 3D descriptors)\n",
    "        mol = Chem.AddHs(mol)  # Add hydrogens\n",
    "        if AllChem.EmbedMolecule(mol, AllChem.ETKDG()) == 0:  # Ensure embedding succeeds\n",
    "            desc[\"RadiusOfGyration\"] = rdMolDescriptors.CalcRadiusOfGyration(mol)  # 3D Descriptor\n",
    "            desc[\"Asphericity\"] = rdMolDescriptors.CalcAsphericity(mol)  # 3D Descriptor\n",
    "            desc[\"Eccentricity\"] = rdMolDescriptors.CalcEccentricity(mol)  # 3D Descriptor\n",
    "        else:\n",
    "            desc[\"RadiusOfGyration\"] = None\n",
    "            desc[\"Asphericity\"] = None\n",
    "            desc[\"Eccentricity\"] = None\n",
    "\n",
    "        return desc\n",
    "    return None\n",
    "\n",
    "# Apply the function to create a descriptor DataFrame\n",
    "descriptor_list = []\n",
    "for idx, row in data.iterrows():\n",
    "    desc = get_descriptors(row[\"SMILES\"])\n",
    "    if desc is not None:\n",
    "        desc[\"SMILES\"] = row[\"SMILES\"]  # Track valid SMILES\n",
    "        desc[\"Solubility\"] = row[\"Solubility\"]\n",
    "        descriptor_list.append(desc)\n",
    "\n",
    "# Create final DataFrame\n",
    "df = pd.DataFrame(descriptor_list).dropna()\n",
    "print(f\"Valid molecules: {len(df)}\")\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"molecular_descriptors.csv\", index=False)\n",
    "print(\"Saved descriptors to molecular_descriptors.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My other failed trys:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "### Load the dataset\n",
    "data = pd.read_csv(\"sample_solubility_2.csv\")\n",
    "\n",
    "### Function to convert SMILES to molecules and calculate descriptors\n",
    "def get_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        # Calculate descriptors (returns a dictionary)\n",
    "        descriptors = Descriptors.CalcMolDescriptors(mol)\n",
    "        return descriptors\n",
    "    else:\n",
    "        return None  # Skip invalid SMILES\n",
    "\n",
    "### Apply the function to create a descriptor DataFrame\n",
    "descriptor_list = []\n",
    "for idx, row in data.iterrows():\n",
    "    desc = get_descriptors(row[\"SMILES\"])\n",
    "    if desc is not None:\n",
    "        desc[\"SMILES\"] = row[\"SMILES\"]  # Track valid SMILES\n",
    "        desc[\"Solubility\"] = row[\"Solubility\"]\n",
    "        descriptor_list.append(desc)\n",
    "\n",
    "### Create final DataFrame\n",
    "df = pd.DataFrame(descriptor_list).dropna()\n",
    "print(f\"Valid molecules: {len(df)}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "This code gave me better test R2. However the current code improved my train R2 with increasing features.\n",
    "\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "\n",
    "### Load the dataset\n",
    "data = pd.read_csv(\"sample_solubility_2.csv\")\n",
    "\n",
    "def get_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        desc = Descriptors.CalcMolDescriptors(mol)\n",
    "        # Corrected Polar Surface Area Calculation\n",
    "        desc[\"PolarSurfaceArea\"] = rdMolDescriptors.CalcTPSA(mol)\n",
    "        return desc\n",
    "    return None\n",
    "\n",
    "### Apply the function to create a descriptor DataFrame\n",
    "descriptor_list = []\n",
    "for idx, row in data.iterrows():\n",
    "    desc = get_descriptors(row[\"SMILES\"])\n",
    "    if desc is not None:\n",
    "        desc[\"SMILES\"] = row[\"SMILES\"]  # Track valid SMILES\n",
    "        desc[\"Solubility\"] = row[\"Solubility\"]\n",
    "        descriptor_list.append(desc)\n",
    "\n",
    "### Create final DataFrame\n",
    "df = pd.DataFrame(descriptor_list).dropna()\n",
    "print(f\"Valid molecules: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess    \n",
    "Main parts:  \n",
    "1. Split\n",
    "2. Normalize (if didn't in previous part)  \n",
    "Had major problams with this part.  \n",
    "The changes I can make to improve my results:    \n",
    "  a. remove ouliers: Didn't work well with my sample.  \n",
    "b. Selecting best features while omitting others to avoid overfitting. I have to recieve the name of selected features.  \n",
    "c. Handle missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your generated descriptor data\n",
    "df = pd.read_csv(\"molecular_descriptors.csv\")\n",
    "\n",
    "# Split into features (X) and target (y)\n",
    "X = df.drop([\"SMILES\", \"Solubility\"], axis=1)\n",
    "y = df[\"Solubility\"]\n",
    "\n",
    "# Handle missing values (if any)\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Split into train/test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train = (96, 221) , X_test = (24, 221), y_train = (96,), y_test = (24,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train = {X_train.shape} , X_test = {X_test.shape}, y_train = {y_train.shape}, y_test = {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96, 221), (96, 10), (91,))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature selection\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Decreasing the number of features from 221 to 10\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(X_train)\n",
    "\n",
    "X_new_train= pca.transform(X_train)\n",
    "X_new_test = pca.transform(X_test)\n",
    "#y_new_train = y_train_clean\n",
    "X_train.shape , X_new_train.shape, y_new_train.shape\n",
    "#Check the decrease in features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some advanced code to remove ouliers whitch didn't work well:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import PowerTransformer, RobustScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"molecular_descriptors.csv\")\n",
    "X = df.drop([\"SMILES\", \"Solubility\"], axis=1)\n",
    "y = df[\"Solubility\"]\n",
    "\n",
    "# 1. Initial Split (preserve data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Conservative Preprocessing\n",
    "preprocessor = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),  # Handle missing values\n",
    "    VarianceThreshold(threshold=0.1),  # Remove low-variance features\n",
    "    PowerTransformer(method=\"yeo-johnson\"),  # Make features more Gaussian\n",
    "    IsolationForest(contamination=0.05, random_state=42)  # Mild outlier detection\n",
    ")\n",
    "\n",
    "# 3. Fit on training data ONLY\n",
    "outlier_mask = preprocessor.fit_predict(X_train)\n",
    "\n",
    "# 4. Filter training data (keep inliers AND \"mild\" outliers)\n",
    "X_train_clean = X_train[outlier_mask == 1]\n",
    "y_train_clean = y_train[outlier_mask == 1]\n",
    "print(f\"Retained {len(X_train_clean)} samples after cleaning\")\n",
    "\n",
    "# 5. Final preprocessing for modeling\n",
    "final_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    PowerTransformer(),\n",
    "    RobustScaler()\n",
    ")\n",
    "\n",
    "X_train_preprocessed = final_transformer.fit_transform(X_train_clean)\n",
    "X_test_preprocessed = final_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from scipy import stats\n",
    "\n",
    "# Load your generated descriptor data\n",
    "df = pd.read_csv(\"molecular_descriptors.csv\")\n",
    "\n",
    "# 1. Split into features (X) and target (y)\n",
    "X = df.drop(columns=[\"Solubility\", \"SMILES\"])  # Remove target and identifier\n",
    "y = df[\"Solubility\"]\n",
    "feature_names = X.columns.tolist()  # Save original feature names\n",
    "\n",
    "# 2. Split into train/test sets FIRST (critical for valid preprocessing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 3. Handle missing values using training set statistics\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame to retain feature names\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed, columns=feature_names)\n",
    "X_test_imputed = pd.DataFrame(X_test_imputed, columns=feature_names)\n",
    "\n",
    "# 4. Remove outliers using Z-scores (applied only to training data)\n",
    "#z_scores = np.abs(stats.zscore(X_train_imputed))\n",
    "#outlier_mask = (z_scores < 3).all(axis=1)  # Keep rows where all features |Z| < 3\n",
    "\n",
    "#X_train_clean = X_train_imputed[outlier_mask]\n",
    "#y_train_clean = y_train[outlier_mask]\n",
    "#print(f\"Removed {len(X_train) - len(X_train_clean)} outliers\")\n",
    "\n",
    "# 5. Feature selection using cleaned training data\n",
    "selector = SelectKBest(score_func=f_regression, k=10)\n",
    "X_train_selected = selector.fit_transform(X_train_clean, y_train_clean)\n",
    "X_test_selected = selector.transform(X_test_imputed)\n",
    "\n",
    "# Get selected feature names\n",
    "selected_features = X_train_clean.columns[selector.get_support()]\n",
    "print(\"\\nSelected features:\", selected_features.tolist())\n",
    "\n",
    "# 6. Final data shapes\n",
    "print(\"\\nFinal shapes:\")\n",
    "print(f\"Training set: {X_train_selected.shape} (features), {y_train_clean.shape} (target)\")\n",
    "print(f\"Test set: {X_test_selected.shape} (features), {y_test.shape} (target)\")\n",
    "\n",
    "# Now ready for model training!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Split into features (X) and target (y)\n",
    "X = df.drop([\"SMILES\", \"Solubility\"], axis=1)\n",
    "y = df[\"Solubility\"]\n",
    "\n",
    "# Assuming X is a DataFrame (before splitting)\n",
    "feature_names = X.columns.tolist()  # Save column names here!\n",
    "\n",
    "# Handle missing values (if any)\n",
    "# Replace missing values using a descriptive statistic like median, mean or...\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Remove outliers:\n",
    "from scipy import stats  \n",
    "# Keep data within 3 standard deviations\n",
    "#df_clean = df_clean[(np.abs(stats.zscore(df_clean[\"Solubility\"])) < 3)]    \n",
    "\n",
    "# Split into train/test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Before feature selection\n",
    "print(\"Original X_train shape:\", X_train.shape)  # e.g., (800, 221)\n",
    "\n",
    "# Select features\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "selector = SelectKBest(f_regression, k=10)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)  # Output is NumPy array\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# After feature selection\n",
    "print(\"New X_train shape:\", X_train.shape)       # Should be (800, 10)\n",
    "print(\"New X_test shape:\", X_test.shape)         # Should be (200, 10)\n",
    "\n",
    "# Get selected feature NAMES\n",
    "selected_mask = selector.get_support()  # Boolean array of selected features\n",
    "selected_features = X_train.columns[selected_mask]  # Use X_train (DataFrame) columns\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# After outlier removal, use CLEANED TARGETS\n",
    "X_new_train = X_train_clean  # Your cleaned features (91 samples)\n",
    "y_new_train = y_train_clean  # Must use matching cleaned targets (91 samples)\n",
    "\n",
    "# Verify shapes match\n",
    "print(f\"X shape: {X_new_train.shape}, y shape: {y_new_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the model\n",
    "I used GridSearchCV to optimize the parameters of my randomforest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=10, min_samples_split=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=10, min_samples_split=5, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=10, min_samples_split=5, random_state=42)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "# Initialize and fit grid search\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='neg_root_mean_squared_error')\n",
    "grid_search.fit(X_new_train, y_train)\n",
    "\n",
    "# Get best model\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Now use best_model for predictions\n",
    "best_model.fit(X_new_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you couldn't run calculate calculate_regression_metrics, Do these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "#Verify Data Types\n",
    "print(y_train.dtype)  # Should output `float64` or `int64`\n",
    "print(y_test.dtype)   # Should not output `object`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Fix during data loading\n",
    "#If your Solubility column is read as strings (due to invalid entries in the CSV), convert it:\n",
    "df = pd.read_csv(\"sample_solubility.csv\")\n",
    "df[\"Solubility\"] = pd.to_numeric(df[\"Solubility\"], errors=\"coerce\")  # Convert to numeric\n",
    "df = df.dropna(subset=[\"Solubility\"])  # Drop invalid rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))  # If it's a DataFrame, use .values. If it's an array, skip.\n",
    "# .values:\n",
    "#Ensure Input Shapes\n",
    "# Check that X_train, X_test, y_train, and y_test are NumPy arrays or Pandas DataFrames (not lists or other objects):\n",
    "# Convert to NumPy arrays if needed\n",
    "#X_train = X_train.values\n",
    "#X_test = X_test.values\n",
    "#y_train = y_train.values.ravel()  # Flatten to 1D array\n",
    "#y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Skip .values! Use this instead:\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE (Root Mean Squared Error): Measures the average prediction error (lower = better).\n",
    "Example: RMSE = 0.5 means predictions are off by ~0.5 units (e.g., logS) on average.<br>\n",
    "<br> \n",
    "\n",
    "R² (R-squared): Measures how much variance your model explains (1 = perfect, 0 = no better than the mean). <br>Train R² ≈ Test R² (e.g., Train R² = 0.85, Test R² = 0.80). Test R² ≥ 0.7 is often good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "def calculate_regression_metrics(y_train, y_test, y_pred_train, y_pred_test):\n",
    "    # Calculate metrics for training set\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    rmse_train = np.sqrt(mse_train)  # Compute RMSE manually\n",
    "    #rmse_train = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    \n",
    "    # Calculate metrics for test set\n",
    "    mse_test = mean_squared_error(y_train, y_pred_train)\n",
    "    rmse_test = np.sqrt(mse_test)  # Compute RMSE manually\n",
    "    #rmse_test = mean_squared_error(y_test, y_pred_test, squared=False)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    print(f\"Train RMSE: {rmse_train:.2f}, Train R²: {r2_train:.2f}\")\n",
    "    print(f\"Test RMSE: {rmse_test:.2f}, Test R²: {r2_test:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Train RMSE: 0.03, Train R²: 0.95\n",
      "Test RMSE: 0.03, Test R²: 0.58\n"
     ]
    }
   ],
   "source": [
    "# Predict solubilities\n",
    "y_pred_train_rf = best_model.predict(X_new_train)\n",
    "y_pred_test_rf = best_model.predict(X_new_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "#calculate_regression_metrics(y_train, y_test, y_pred_train_rf, y_pred_test_rf)\n",
    "calculate_regression_metrics(y_train, y_test, y_pred_train_rf, y_pred_test_rf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
